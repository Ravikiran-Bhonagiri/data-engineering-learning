# Day 4: Branching, XComs & Dynamic Workflows

**Time:** 1-2 hours  
**Goal:** Build advanced DAG patterns with conditional logic and dynamic tasks.

---

## ğŸŒ¿ Branching (Conditional Execution)

### BranchPythonOperator

```python
from datetime import datetime
from airflow import DAG
from airflow.operators.python import BranchPythonOperator, PythonOperator

def choose_path():
    """Decide which path to take"""
    from random import choice
    return 'path_a' if choice([True, False]) else 'path_b'

def task_a():
    print("Executing Path A")

def task_b():
    print("Executing Path B")

with DAG('branching_example', start_date=datetime(2025, 12, 1), schedule_interval=None) as dag:
    
    branch = BranchPythonOperator(
        task_id='branch',
        python_callable=choose_path,
    )
    
    a = PythonOperator(task_id='path_a', python_callable=task_a)
    b = PythonOperator(task_id='path_b', python_callable=task_b)
    
    branch >> [a, b]
```

**Key points:**
- `choose_path()` returns the `task_id` to execute
- Only ONE branch runs, others are skipped

---

## ğŸ’¬ XComs (Cross-Communication)

### Push & Pull Data

```python
from airflow.decorators import dag, task
from datetime import datetime

@dag('xcom_example', start_date=datetime(2025, 12, 1), schedule=None)
def pipeline():
    
    @task
    def generate_data():
        data = {'users': 1000, 'revenue': 50000}
        return data  # Automatically pushed to XCom
    
    @task
    def process_data(data):  # Automatically pulls from XCom
        print(f"Processing {data['users']} users")
        print(f"Revenue: ${data['revenue']}")
        return data['revenue'] * 1.1  # 10% growth
    
    @task
    def send_report(revenue):
        print(f"Projected revenue: ${revenue:,.2f}")
    
    raw = generate_data()
    processed = process_data(raw)
    send_report(processed)

dag = pipeline()
```

### Manual XCom (Classic API)

```python
def push_value(**context):
    context['ti'].xcom_push(key='my_key', value=12345)

def pull_value(**context):
    value = context['ti'].xcom_pull(key='my_key', task_ids='push_task')
    print(f"Pulled value: {value}")
```

**XCom limitations:**
- Stored in metadata database (not for large data!)
- Max size: ~48KB (depends on DB)
- For large data, use S3/GCS and pass the path

---

## ğŸ”„ Dynamic Task Mapping

### Example: Process Multiple Files

```python
from airflow.decorators import dag, task
from datetime import datetime

@dag('dynamic_mapping', start_date=datetime(2025, 12, 1), schedule=None)
def pipeline():
    
    @task
    def get_files():
        return ['file1.csv', 'file2.csv', 'file3.csv', 'file4.csv']
    
    @task
    def process_file(filename):
        print(f"Processing {filename}...")
        # Simulate processing
        return f"Processed_{filename}"
    
    @task
    def combine_results(processed_files):
        print(f"Combined {len(processed_files)} files")
        print(processed_files)
    
    files = get_files()
    # Creates 4 parallel tasks dynamically
    results = process_file.expand(filename=files)
    combine_results(results)

dag = pipeline()
```

**What happens:**
```
get_files()
    â†“
process_file[0] (file1.csv) â”€â”
process_file[1] (file2.csv) â”€â”¤
process_file[2] (file3.csv) â”€â”¼â†’ combine_results()
process_file[3] (file4.csv) â”€â”˜
```

---

## ğŸ¯ Complete Example: Data Validation with Branching

```python
from airflow.decorators import dag, task
from airflow.operators.python import BranchPythonOperator
from datetime import datetime

@dag('data_validation_pipeline', start_date=datetime(2025, 12, 1), schedule='@daily', catchup=False)
def pipeline():
    
    @task
    def check_data_quality():
        """Simulate data quality check"""
        row_count = 1000  # Simulated
        error_rate = 0.05  # 5% errors
        
        return {
            'row_count': row_count,
            'error_rate': error_rate,
            'is_valid': error_rate < 0.10  # <10% error threshold
        }
    
    def decide_path(**context):
        """Branch based on data quality"""
        quality = context['ti'].xcom_pull(task_ids='check_data_quality')
        if quality['is_valid']:
            return 'proceed_with_load'
        else:
            return 'send_alert'
    
    @task
    def proceed_with_load():
        print("âœ… Data quality OK - Loading to warehouse")
    
    @task
    def send_alert():
        print("âŒ Data quality issues - Sending alert")
    
    @task
    def cleanup():
        print("Cleanup complete")
    
    # Build the flow
    quality_check = check_data_quality()
    
    branch = BranchPythonOperator(
        task_id='branch_on_quality',
        python_callable=decide_path,
    )
    
    load = proceed_with_load()
    alert = send_alert()
    clean = cleanup()
    
    quality_check >> branch >> [load, alert] >> clean

dag = pipeline()
```

---

## âœï¸ Practice Exercise

**Build a multi-region deployment DAG:**

```python
@dag('deploy_to_regions', start_date=datetime(2025, 12, 1), schedule=None)
def pipeline():
    
    @task
    def get_regions():
        return ['us-east-1', 'us-west-2', 'eu-west-1']
    
    @task
    def deploy_to_region(region):
        print(f"Deploying to {region}...")
        # Simulate deployment
        import time
        time.sleep(2)
        return f"{region}: SUCCESS"
    
    @task
    def verify_deployment(region):
        print(f"Verifying {region}...")
        return True
    
    @task
    def send_notification(statuses):
        print(f"Deployment complete: {statuses}")
    
    regions = get_regions()
    deployed = deploy_to_region.expand(region=regions)
    verified = verify_deployment.expand(region=regions)
    
    deployed >> verified >> send_notification(verified)
```

---

## ğŸ¯ Key Takeaways

âœ… **Branching:** Execute different paths with `BranchPythonOperator`  
âœ… **XComs:** Pass small data between tasks  
âœ… **Dynamic Mapping:** Create parallel tasks from lists  
âœ… **TaskFlow API:** Automatic XCom handling  
âœ… **Data Size:** Use external storage (S3) for large data  

---

**Next:** `02_Day_05.md` - ETL Pipelines & External Integrations! ğŸ”—
