# Day 9: Security & Administration

**Time:** 1-2 hours  
**Goal:** Secure the platform: Secrets, Networking, and Policies.

---

## ğŸ¤« Secret Management

Never hardcode credentials in notebooks!

**Secret Scope:** A vault for keys.
1. **Azure Key Vault Backed.**
2. **Databricks Backed** (Encrypted DB).

**CLI Command:**
```bash
databricks secrets create-scope --scope my_scope
databricks secrets put --scope my_scope --key api_token
```

**Usage (Python):**
```python
password = dbutils.secrets.get(scope="my_scope", key="api_token")
```
*Note: Printing `password` returns `[REDACTED]`.*

---

## ğŸŒ Networking Basics

1. **Private Link:** Connect Databricks Control Plane to Data Plane privately (no public internet).
2. **IP Access Lists:** Allow only corporate VPN IPs to access the Workspace UI.
3. **VNet Injection:** Deploy Databricks clusters into your own specific VPC/Subnet.

---

## ğŸ‘® Cluster Policies

Prevent users from spinning up expensive clusters.

**Example Policy (JSON):**
```json
{
  "spark_conf.spark.databricks.cluster.profile": {
    "type": "fixed",
    "value": "singleNode"
  },
  "instance_pool_id": {
    "type": "forbidden"
  },
  "autotermination_minutes": {
    "type": "range",
    "maxValue": 60,
    "defaultValue": 30
  }
}
```
**Effect:** Users MUST turn on autotermination (<60m) and cannot use instance pools.

---

## ğŸ— Identity Federation (SCIM)

Sync users/groups from your IdP (Okta, Azure AD) to the Databricks Account Console.
- **Account Group:** "Data Engineers"
- **Workspace Assignment:** Assign "Data Engineers" to `dev-workspace` and `prod-workspace`.

---

## ğŸ¯ Interview Q&A

**Q: How do you prevent developers from seeing production data?**
A: Use Unity Catalog.
1. Create a `prod` catalog.
2. Grant `SELECT` only to the `prod_service_principal` (for jobs).
3. Developers get `SELECT` on `dev` catalog.
4. For debugging, use Dynamic Views to mask PII in Prod if read access is strictly needed.

**Q: What is SCIM?**
A: System for Cross-domain Identity Management. It automates user provisioning. If a user leaves the company and is removed from AD/Okta, SCIM automatically removes them from Databricks.

**Q: Can you access secrets in SQL?**
A: Not directly in standard SQL for security reasons (to prevent leakage). However, you can configure Spark Conf to use secrets (`spark.hadoop.fs.s3a.access.key = {{secrets/scope/key}}`) so the connection works without the user seeing the key.

---

**Next:** [Day 10: Interview Masterclass](./02_Day_10.md)
