# Day 8: MLflow & Machine Learning

**Time:** 1-2 hours  
**Goal:** Manage the ML lifecycle: Tracking, Registry, and Serving.

---

## üî¨ MLflow Components

Databricks offers a fully managed MLflow service.

1. **Tracking:** Record experiments (params, metrics, artifacts).
2. **Models:** Standard format to package models.
3. **Registry:** Manage model lifecycle (Staging -> Prod).
4. **Serving:** Expose models as REST APIs.

---

## üõ† Hands-on: Tracking an Experiment

Using a **Machine Learning** cluster (DBR ML).

```python
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestRegressor

# Enable Autologging (Captures params metrics automatically)
mlflow.sklearn.autolog()

with mlflow.start_run(run_name="my_first_run"):
    # Load data
    X, y = load_data()
    
    # Train
    rf = RandomForestRegressor(n_estimators=100)
    rf.fit(X, y)
    
    # Optional: Log custom metric
    mlflow.log_metric("custom_score", 0.95)
```

**View Results:** Go to the "Experiments" sidebar to see the run, compare runs, and view charts.

---

## üè™ Model Registry & Unity Catalog

Models are now governed assets in Unity Catalog!

```python
# Register model to UC
mlflow.set_registry_uri("databricks-uc")

model_name = "dev_catalog.ml.churn_prediction"
mlflow.register_model(
    "runs:/<run_id>/model",
    model_name
)
```

**Lifecycle:**
- **Aliases:** Tag versions as `champion` or `challenger`. (Old `Staging`/`Prod` stages are legacy).

```python
client = mlflow.MlflowClient()
client.set_registered_model_alias(model_name, "champion", 1)
```

---

## üçΩ Model Serving

Deploy a model as a serverless Real-Time Inference Endpoint.
1. UI: Serving -> Create Endpoint.
2. Select Model: `dev_catalog.ml.churn_prediction`.
3. Databricks spins up a serverless container exposing a REST API.

---

## ü§ñ Feature Store

A centralized repo for feature data (prevent training-serving skew).
- **Write:** Create feature table (Delta Table).
- **Train:** Look up features by primary key.
- **Serve:** Automatically lookup features at inference time.

---

## üéØ Interview Q&A

**Q: What is "Autologging" in Databricks?**
A: `mlflow.autolog()` automatically captures parameters, metrics, model artifacts, and environment details (requirements.txt) without manual logging statements. It works for standard libs like Scikit-learn, XGBoost, and Spark MLlib.

**Q: How does Unity Catalog integrate with ML?**
A: Models are stored as objects in the 3-level namespace (`catalog.schema.model`). This means you use standard SQL `GRANT` statements to control who can register, read, or invoke models, just like tables.

---

**Next:** [Day 9: Admin & Security](./02_Day_09.md)
