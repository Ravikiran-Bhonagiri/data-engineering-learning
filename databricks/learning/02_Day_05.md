# Day 5: Performance Tuning on Databricks

**Time:** 2 hours  
**Goal:** Master the specific optimizations available in Databricks Runtime (DBR).

---

## âš¡ Photon Engine

**What is it?**
A vectorized query engine rewritten in C++ (replacing the Java row-based execution).

**When to use:**
- SQL Workloads.
- DataFrames with standard operations (filter, join, agg).
- **Not for:** RDDs, complex UDFs not utilizing vectorization.

**How to enable:** checkbox "Use Photon Acceleration" when creating a cluster.

---

## ðŸŽ² Partitions vs Z-Order vs Clustering

See Day 2, but deeper dive:

**Small File Problem:**
Delta Lake hates millions of 1KB files.
- **Solution 1:** `OPTIMIZE` (runs compaction).
- **Solution 2:** Auto-Optimize (writes slower, but compacts on writes).
  ```sql
  SET spark.databricks.delta.optimizeWrite.enabled = true;
  SET spark.databricks.delta.autoCompact.enabled = true;
  ```

---

## ðŸ§  Adaptive Query Execution (AQE)

AQE is enabled by default in Spark 3.0+. It optimizes query plans *during* execution based on runtime stats.

1. **Dynamically Coalesce Shuffle Partitions:**
   - If user sets 200 partitions but data is small, AQE combines them to 5.
.
2. **Dynamically Switch Join Strategies:**
   - If one side of a SortMergeJoin is smaller than expected, switch to BroadcastHashJoin.

3. **Dynamically Optimize Skew Joins:**
   - Splits skewed partitions (large keys) into smaller sub-tasks.

---

## ðŸ’¾ Caching on Databricks

### 1. Spark Cache (`.cache()`)
- Stores in Executor Memory.
- Instance based (lost if cluster restarts).

### 2. Disk Cache (formerly Delta Cache)
- Uses local NVMe SSDs on worker nodes.
- Caches **remote files** (parquet/delta) for faster reading.
- Persists as long as the cluster is running, even if Spark restarts.
- **Enabled by default** on certain instance types (L series).

```python
spark.conf.set("spark.databricks.io.cache.enabled", "true")
```

---

## ðŸ•µï¸â€â™‚ï¸ Spark UI & Ganglia

**Diagnosing Issues:**
1. **Driver Overloaded:** Ganglia -> CPU usage on driver is 100%. (Move `collect()` or serial code to workers).
2. **Spill to Disk:** Spark UI -> Stage detail -> "Disk Spill". (Increase memory or partitions).
3. **Shuffle Failure:** "FetchFailedException". (Network issue or OOM).

---

## ðŸŽ¯ Interview Q&A

**Q: What is the difference between Spark Cache and Disk Cache (Delta Cache)?**
A: Spark Cache (`cache()`) stores uncompressed *result data* (post-transformation) in RAM. Disk Cache stores *raw input files* (copy of S3/ADLS data) on local SSDs in a proprietary fast format. Disk Cache is purely for read acceleration of source data.

**Q: How does AQE handle data skew?**
A: AQE detects when a shuffle partition is significantly larger than others (skew). It breaks that partition into smaller chunks and replicates the corresponding rows from the other table (if joining), enabling parallel processing of the skewed key.

**Q: Why is my "Broadcast Join" timing out?**
A: You likely forced a broadcast on a table larger than the driver's memory, or the stats were outdated and Spark thought it was small. Use `ANALYZE TABLE COMPUTE STATISTICS` or increase the broadcast threshold/timeout (or disable broadcast).

---

**Next:** [Day 6: Delta Live Tables (DLT)](./02_Day_06.md)
