# ğŸš€ PySpark Learning Path

**Goal:** Master Apache Spark with Python for big data processing.  
**Prerequisites:** Intermediate Python skills, basic SQL knowledge.

---

## ğŸ“š Course Structure

### Part 1: Foundation (Start Here)
**File:** `01_Foundation.md`
- Why PySpark? (Pandas limitations â†’ distributed computing)
- Spark Architecture (Driver, Executors, Cluster Manager)
- PySpark Ecosystem (Spark SQL, MLlib, Streaming)

---

### Part 2: 10-Day Intensive Course
**Files:** `02_Day_00.md` through `02_Day_09.md`

| Day | Topic |
|-----|-------|
| **Day 00** | What is PySpark & Why It Matters |
| **Day 01** | Installation & First Steps |
| **Day 02** | Mastering RDDs |
| **Day 03** | DataFrames Deep Dive |
| **Day 04** | Spark SQL |
| **Day 05** | Structured Streaming |
| **Day 06** | MLlib Basics |
| **Day 07** | ML Pipelines & Feature Engineering |
| **Day 08** | Delta Lake & Data Lakehouse |
| **Day 09** | Production Deployment & Cluster Management |

---

### Part 3: Quick Reference
**File:** `03_QUICK_Reference.md`
- Essential commands & syntax
- Common patterns
- Interview Q&A

---

### Part 4: Complete Examples
**File:** `04_Complete_Examples.md`
- ETL Pipeline (CSV â†’ Transform â†’ Parquet)
- Real-time Analytics (Streaming)
- ML Pipeline (Classification)

---

### Part 5: Practice Exercises
**File:** `05_Practice_Exercises.md`
- 5 progressively difficult challenges (no solutions)

---

### Supplemental Guides
| File | Topic |
|------|-------|
| `06_Installation_Guide.md` | Detailed setup (pip, Docker, Databricks) |
| `07_Performance_Tuning.md` | Optimization deep dive |
| `08_Databricks_Guide.md` | Managed Spark on Databricks |
| `09_Troubleshooting_Extended.md` | Common errors and fixes |
| `10_Delta_Lake_Advanced.md` | Delta Lake patterns |

---

## ğŸš€ Recommended Workflow

1. **Foundation:** Read `01_Foundation.md` to understand the "why"
2. **Learn:** Complete Days 0-9 sequentially (1-2 hours/day)
3. **Practice:** Build projects from examples
4. **Reference:** Use `03_QUICK_Reference.md` before interviews

**Total Time:** ~20-25 hours for mastery.

---

## ğŸ“ Folder Structure

```
pyspark/learning/
â”œâ”€â”€ README.md                       â† You are here
â”œâ”€â”€ 01_Foundation.md                â† Part 1: Start here
â”œâ”€â”€ 02_Day_00.md - 02_Day_09.md     â† Part 2: 10-Day Course
â”œâ”€â”€ 03_QUICK_Reference.md           â† Part 3: Cheat Sheet
â”œâ”€â”€ 04_Complete_Examples.md         â† Part 4: 3 Projects
â”œâ”€â”€ 05_Practice_Exercises.md        â† Part 5: 5 Challenges
â”œâ”€â”€ 06_Installation_Guide.md        â† Supplemental
â”œâ”€â”€ 07_Performance_Tuning.md        â† Supplemental
â”œâ”€â”€ 08_Databricks_Guide.md          â† Supplemental
â”œâ”€â”€ 09_Troubleshooting_Extended.md  â† Supplemental
â”œâ”€â”€ 10_Delta_Lake_Advanced.md       â† Supplemental
â””â”€â”€ projects/                       â† ğŸ”¥ Hands-on Projects
    â”œâ”€â”€ 01_etl_pipeline.py
    â”œâ”€â”€ 02_streaming_analytics.py
    â”œâ”€â”€ 03_ml_churn_prediction.py
    â”œâ”€â”€ 04_data_quality_pipeline.py
    â”œâ”€â”€ 05_medallion_architecture.py
    â””â”€â”€ 06_recommendation_engine.py
```

---

## ğŸ¯ Why Learn PySpark?

- **Industry Standard:** Used by Netflix, Uber, Airbnb for big data
- **Scale:** Process terabytes of data across clusters
- **Python-Native:** Use familiar syntax with distributed power
- **High Demand:** Critical skill for Data Engineering roles

---

**Start your journey:** Open `01_Foundation.md` ğŸš€
